0 [Training loss: 0.037941, acc.: 14.53%, precission: 5.34%, recall: 94.24%, f1: 10.07%]
0 [Validation loss: 0.031500, acc.: 9.17%, precission: 4.02%, recall: 98.21%, f1: 7.69%]
1 [Training loss: 0.037564, acc.: 14.29%, precission: 5.67%, recall: 95.30%, f1: 10.63%]
1 [Validation loss: 0.030901, acc.: 8.88%, precission: 4.02%, recall: 98.55%, f1: 7.70%]
2 [Training loss: 0.034378, acc.: 12.67%, precission: 5.13%, recall: 96.89%, f1: 9.72%]
2 [Validation loss: 0.030456, acc.: 8.38%, precission: 4.00%, recall: 98.79%, f1: 7.67%]
3 [Training loss: 0.033653, acc.: 12.81%, precission: 5.57%, recall: 98.08%, f1: 10.50%]
3 [Validation loss: 0.030127, acc.: 7.52%, precission: 3.96%, recall: 98.86%, f1: 7.59%]
4 [Training loss: 0.031915, acc.: 10.93%, precission: 5.19%, recall: 98.66%, f1: 9.84%]
4 [Validation loss: 0.029593, acc.: 6.87%, precission: 3.93%, recall: 98.95%, f1: 7.53%]
5 [Training loss: 0.032314, acc.: 11.37%, precission: 6.04%, recall: 99.04%, f1: 11.26%]
5 [Validation loss: 0.028647, acc.: 6.65%, precission: 3.92%, recall: 98.97%, f1: 7.51%]
6 [Training loss: 0.028815, acc.: 9.88%, precission: 5.00%, recall: 99.41%, f1: 9.44%]
6 [Validation loss: 0.027715, acc.: 6.65%, precission: 3.92%, recall: 98.97%, f1: 7.51%]
7 [Training loss: 0.027436, acc.: 11.12%, precission: 5.44%, recall: 99.56%, f1: 10.29%]
7 [Validation loss: 0.026555, acc.: 7.28%, precission: 3.94%, recall: 98.66%, f1: 7.54%]
8 [Training loss: 0.024650, acc.: 11.70%, precission: 4.97%, recall: 99.67%, f1: 9.46%]
8 [Validation loss: 0.025365, acc.: 11.44%, precission: 4.02%, recall: 96.87%, f1: 7.70%]
9 [Training loss: 0.022433, acc.: 17.08%, precission: 5.70%, recall: 99.66%, f1: 10.75%]
9 [Validation loss: 0.024367, acc.: 23.09%, precission: 4.34%, recall: 91.52%, f1: 8.28%]
10 [Training loss: 0.020058, acc.: 29.81%, precission: 6.86%, recall: 99.22%, f1: 12.74%]
10 [Validation loss: 0.024227, acc.: 42.07%, precission: 5.18%, recall: 82.03%, f1: 9.73%]
11 [Training loss: 0.018426, acc.: 44.06%, precission: 7.51%, recall: 98.53%, f1: 13.94%]
11 [Validation loss: 0.025289, acc.: 61.62%, precission: 6.76%, recall: 70.51%, f1: 12.33%]
12 [Training loss: 0.016914, acc.: 59.74%, precission: 10.88%, recall: 97.60%, f1: 19.46%]
12 [Validation loss: 0.023887, acc.: 62.26%, precission: 7.17%, recall: 74.90%, f1: 13.09%]
13 [Training loss: 0.015159, acc.: 66.58%, precission: 12.33%, recall: 97.30%, f1: 21.81%]
13 [Validation loss: 0.025674, acc.: 78.99%, precission: 10.40%, recall: 61.67%, f1: 17.75%]
14 [Training loss: 0.014292, acc.: 70.87%, precission: 12.95%, recall: 98.13%, f1: 22.66%]
14 [Validation loss: 0.025554, acc.: 83.20%, precission: 12.97%, recall: 61.43%, f1: 21.20%]
15 [Training loss: 0.012965, acc.: 79.43%, precission: 20.42%, recall: 97.76%, f1: 33.67%]
15 [Validation loss: 0.024507, acc.: 79.32%, precission: 12.60%, recall: 67.05%, f1: 20.73%]
16 [Training loss: 0.012393, acc.: 82.69%, precission: 22.95%, recall: 97.57%, f1: 36.54%]
16 [Validation loss: 0.025081, acc.: 79.85%, precission: 13.70%, recall: 67.77%, f1: 22.03%]
17 [Training loss: 0.010838, acc.: 81.36%, precission: 18.23%, recall: 98.45%, f1: 29.89%]
17 [Validation loss: 0.029915, acc.: 91.12%, precission: 20.57%, recall: 53.86%, f1: 28.79%]
18 [Training loss: 0.010385, acc.: 86.97%, precission: 27.46%, recall: 97.56%, f1: 42.57%]
18 [Validation loss: 0.026896, acc.: 83.68%, precission: 16.83%, recall: 65.73%, f1: 25.39%]
19 [Training loss: 0.009938, acc.: 88.37%, precission: 30.74%, recall: 97.60%, f1: 46.50%]
19 [Validation loss: 0.028506, acc.: 86.18%, precission: 18.54%, recall: 63.52%, f1: 27.08%]
